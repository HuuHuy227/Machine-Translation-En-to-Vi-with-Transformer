{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install the dependencies.\n!pip install underthesea","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-11-18T15:46:39.087823Z","iopub.execute_input":"2022-11-18T15:46:39.088568Z","iopub.status.idle":"2022-11-18T15:46:54.499062Z","shell.execute_reply.started":"2022-11-18T15:46:39.088478Z","shell.execute_reply":"2022-11-18T15:46:54.497892Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting underthesea\n  Downloading underthesea-1.3.5-py3-none-any.whl (11.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hRequirement already satisfied: Click>=6.0 in /opt/conda/lib/python3.7/site-packages (from underthesea) (8.0.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from underthesea) (3.7)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from underthesea) (2.28.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.0.2)\nRequirement already satisfied: unidecode in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.3.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from underthesea) (4.64.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from underthesea) (6.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.0.1)\nCollecting underthesea-core==0.0.5a2\n  Downloading underthesea_core-0.0.5_alpha.2-cp37-cp37m-manylinux2010_x86_64.whl (591 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.7/591.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting python-crfsuite>=0.9.6\n  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click>=6.0->underthesea) (4.13.0)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk->underthesea) (2021.11.10)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (2.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (3.1.0)\nRequirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (1.21.6)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (1.7.3)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=6.0->underthesea) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=6.0->underthesea) (3.8.0)\nInstalling collected packages: underthesea-core, python-crfsuite, underthesea\nSuccessfully installed python-crfsuite-0.9.8 underthesea-1.3.5 underthesea-core-0.0.5a2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re,string\nfrom underthesea import word_tokenize\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom typing import Iterable, List\nfrom gensim.models import KeyedVectors\nfrom torch import Tensor\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Transformer\nfrom torch.nn.utils.rnn import pad_sequence\nfrom timeit import default_timer as timer\nimport math\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-11-18T15:46:54.501881Z","iopub.execute_input":"2022-11-18T15:46:54.502271Z","iopub.status.idle":"2022-11-18T15:46:57.617797Z","shell.execute_reply.started":"2022-11-18T15:46:54.502234Z","shell.execute_reply":"2022-11-18T15:46:57.616873Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_dir = \"../input/englishvietnamese-translation/\"\nen_sents = open(data_dir + 'en_sents', \"r\").read().splitlines()\nvi_sents = open(data_dir + 'vi_sents', \"r\").read().splitlines()\nraw_data = {\n        \"en\": [line for line in en_sents[:170000]], # Only take first 170000 lines\n        \"vi\": [line for line in vi_sents[:170000]],\n    }\ndf = pd.DataFrame(raw_data, columns=[\"en\", \"vi\"])\nprint(len(en_sents))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-18T15:46:57.619307Z","iopub.execute_input":"2022-11-18T15:46:57.619918Z","iopub.status.idle":"2022-11-18T15:46:58.415988Z","shell.execute_reply.started":"2022-11-18T15:46:57.619882Z","shell.execute_reply":"2022-11-18T15:46:58.414907Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"254090\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                  en  \\\n0         Please put the dustpan in the broom closet   \n1                             Be quiet for a moment.   \n2                                          Read this   \n3  Tom persuaded the store manager to give him ba...   \n4        Friendship consists of mutual understanding   \n\n                                                  vi  \n0      xin vui lòng đặt người quét rác trong tủ chổi  \n1                                    im lặng một lát  \n2                                            đọc này  \n3  tom thuyết phục người quản lý cửa hàng trả lại...  \n4             tình bạn bao gồm sự hiểu biết lẫn nhau  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>vi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Please put the dustpan in the broom closet</td>\n      <td>xin vui lòng đặt người quét rác trong tủ chổi</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Be quiet for a moment.</td>\n      <td>im lặng một lát</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Read this</td>\n      <td>đọc này</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Tom persuaded the store manager to give him ba...</td>\n      <td>tom thuyết phục người quản lý cửa hàng trả lại...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Friendship consists of mutual understanding</td>\n      <td>tình bạn bao gồm sự hiểu biết lẫn nhau</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"This dataset provides a set of 254,090 tuples containing an English source sentence, its Vietnamese human translation and we take 170000 set for training and evaluation","metadata":{}},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-11-18T15:46:58.418718Z","iopub.execute_input":"2022-11-18T15:46:58.419109Z","iopub.status.idle":"2022-11-18T15:46:58.441076Z","shell.execute_reply.started":"2022-11-18T15:46:58.419075Z","shell.execute_reply":"2022-11-18T15:46:58.439846Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"en    0\nvi    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"def preprocessing(df): \n  df[\"en\"] = df[\"en\"].apply(lambda ele: ele.translate(str.maketrans('', '', string.punctuation))) # Remove punctuation\n  df[\"vi\"] = df[\"vi\"].apply(lambda ele: ele.translate(str.maketrans('', '', string.punctuation)))  \n  df[\"en\"] = df[\"en\"].apply(lambda ele: ele.lower()) # convert text to lowercase\n  df[\"vi\"] = df[\"vi\"].apply(lambda ele: ele.lower())\n  df[\"en\"] = df[\"en\"].apply(lambda ele: ele.strip()) \n  df[\"vi\"] = df[\"vi\"].apply(lambda ele: ele.strip()) \n  df[\"en\"] = df[\"en\"].apply(lambda ele: re.sub(\"\\s+\", \" \", ele)) \n  df[\"vi\"] = df[\"vi\"].apply(lambda ele: re.sub(\"\\s+\", \" \", ele))\n    \n  return df\n\ndf = preprocessing(df)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-18T15:46:58.442785Z","iopub.execute_input":"2022-11-18T15:46:58.443520Z","iopub.status.idle":"2022-11-18T15:47:01.717241Z","shell.execute_reply.started":"2022-11-18T15:46:58.443485Z","shell.execute_reply":"2022-11-18T15:47:01.716250Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                  en  \\\n0         please put the dustpan in the broom closet   \n1                              be quiet for a moment   \n2                                          read this   \n3  tom persuaded the store manager to give him ba...   \n4        friendship consists of mutual understanding   \n\n                                                  vi  \n0      xin vui lòng đặt người quét rác trong tủ chổi  \n1                                    im lặng một lát  \n2                                            đọc này  \n3  tom thuyết phục người quản lý cửa hàng trả lại...  \n4             tình bạn bao gồm sự hiểu biết lẫn nhau  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en</th>\n      <th>vi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>please put the dustpan in the broom closet</td>\n      <td>xin vui lòng đặt người quét rác trong tủ chổi</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>be quiet for a moment</td>\n      <td>im lặng một lát</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>read this</td>\n      <td>đọc này</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tom persuaded the store manager to give him ba...</td>\n      <td>tom thuyết phục người quản lý cửa hàng trả lại...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>friendship consists of mutual understanding</td>\n      <td>tình bạn bao gồm sự hiểu biết lẫn nhau</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Tokenzing for english which is source language by tokenizer of basic english and vietnamese which is target language by Underthesea library","metadata":{}},{"cell_type":"code","source":"# Create source and target language tokenizer.\nSRC_LANGUAGE = 'en'\nTGT_LANGUAGE = 'vi'\n\n# Place-holders\ntoken_transform = {}\nvocab_transform = {}\n\n# Tokenize for vietnames by underthesea\ndef vi_tokenizer(sentence):\n    tokens = word_tokenize(sentence)\n    return tokens\n\ntoken_transform[SRC_LANGUAGE] = get_tokenizer('basic_english')\ntoken_transform[TGT_LANGUAGE] = get_tokenizer(vi_tokenizer)\n\n# helper function to yield list of tokens\ndef yield_tokens(data_iter: Iterable, language: str) -> List[str]:    \n    for index,data_sample in data_iter:\n        yield token_transform[language](data_sample[language])\n\n# Define special symbols and indices\nUNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n# Make sure the tokens are in order of their indices to properly insert them in vocab\nspecial_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n\nfor ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n    # Training data Iterator\n    train_iter = df.iterrows()\n    # Create torchtext's Vocab object\n    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n                                                    min_freq=1,\n                                                    specials=special_symbols,\n                                                    special_first=True)\n\n# Set UNK_IDX as the default index. This index is returned when the token is not found.\n# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\nfor ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n  vocab_transform[ln].set_default_index(UNK_IDX)","metadata":{"execution":{"iopub.status.busy":"2022-11-18T15:47:01.718717Z","iopub.execute_input":"2022-11-18T15:47:01.719524Z","iopub.status.idle":"2022-11-18T15:48:40.782017Z","shell.execute_reply.started":"2022-11-18T15:47:01.719487Z","shell.execute_reply":"2022-11-18T15:48:40.781001Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Model Defination","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Check whether running on gpu or cpu\n\n# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\nclass PositionalEncoding(nn.Module):\n    def __init__(self,\n                 emb_size: int,\n                 dropout: float = 0.1,\n                 maxlen: int = 5000):\n        super(PositionalEncoding, self).__init__()\n        \n        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n        pos_embedding = torch.zeros((maxlen, emb_size))\n        pos_embedding[:, 0::2] = torch.sin(pos * den)\n        pos_embedding[:, 1::2] = torch.cos(pos * den)\n        pos_embedding = pos_embedding.unsqueeze(-2)\n\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer('pos_embedding', pos_embedding)\n\n    def forward(self, token_embedding: Tensor):\n        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n\n# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\nclass TokenEmbedding(nn.Module):\n    def __init__(self, vocab_size: int, emb_size):\n        super(TokenEmbedding, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_size) \n        self.emb_size = emb_size\n\n    def forward(self, tokens: Tensor):\n        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n\n# Seq2Seq Network\nclass Seq2SeqTransformer(nn.Module):\n    def __init__(self,\n                 num_encoder_layers: int,\n                 num_decoder_layers: int,\n                 emb_size: int,\n                 nhead: int,\n                 src_vocab_size: int,\n                 tgt_vocab_size: int,\n                 dim_feedforward: int = 512,\n                 dropout: float = 0.1):\n        super(Seq2SeqTransformer, self).__init__()\n        self.transformer = Transformer(d_model=emb_size,\n                                       nhead=nhead,\n                                       num_encoder_layers=num_encoder_layers,\n                                       num_decoder_layers=num_decoder_layers,\n                                       dim_feedforward=dim_feedforward,\n                                       dropout=dropout)\n        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n        self.positional_encoding = PositionalEncoding(\n            emb_size, dropout=dropout)\n\n    def forward(self,\n                src: Tensor,\n                trg: Tensor,\n                src_mask: Tensor,\n                tgt_mask: Tensor,\n                src_padding_mask: Tensor,\n                tgt_padding_mask: Tensor,\n                memory_key_padding_mask: Tensor):\n        src_emb = self.positional_encoding(self.src_tok_emb(src))\n        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n        return self.generator(outs)\n   \n    def encode(self, src: Tensor, src_mask: Tensor):\n        return self.transformer.encoder(self.positional_encoding(\n                            self.src_tok_emb(src)), src_mask)\n\n    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n        return self.transformer.decoder(self.positional_encoding(\n                          self.tgt_tok_emb(tgt)), memory,\n                          tgt_mask)","metadata":{"execution":{"iopub.status.busy":"2022-11-18T15:48:40.783478Z","iopub.execute_input":"2022-11-18T15:48:40.783842Z","iopub.status.idle":"2022-11-18T15:48:40.865177Z","shell.execute_reply.started":"2022-11-18T15:48:40.783806Z","shell.execute_reply":"2022-11-18T15:48:40.864276Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def generate_square_subsequent_mask(sz):\n    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n    return mask\n\n\ndef create_mask(src, tgt):\n    src_seq_len = src.shape[0]\n    tgt_seq_len = tgt.shape[0]\n\n    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n\n    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask","metadata":{"execution":{"iopub.status.busy":"2022-11-18T15:48:40.866467Z","iopub.execute_input":"2022-11-18T15:48:40.867143Z","iopub.status.idle":"2022-11-18T15:48:40.875242Z","shell.execute_reply.started":"2022-11-18T15:48:40.867109Z","shell.execute_reply":"2022-11-18T15:48:40.874325Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Define the parameters of the model, instantiate the same and the loss function which is the cross-entropy loss and the optmizer used for training is Adam with β1 = 0.9, β2 = 0.98 and epsilon = 1e−9.","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(0)\nSRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\nTGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\nEMB_SIZE = 512\nNHEAD = 8 # embed_dim must be divisible by num_heads\nFFN_HID_DIM = 512\nBATCH_SIZE = 64\nNUM_ENCODER_LAYERS = 4\nNUM_DECODER_LAYERS = 4\nDROP_OUT = 0.1\n\ntransformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM,DROP_OUT)\n\nfor p in transformer.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)\n\ntransformer = transformer.to(DEVICE)\n\nloss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n\noptimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)","metadata":{"execution":{"iopub.status.busy":"2022-11-18T15:48:40.876815Z","iopub.execute_input":"2022-11-18T15:48:40.877384Z","iopub.status.idle":"2022-11-18T15:48:44.196332Z","shell.execute_reply.started":"2022-11-18T15:48:40.877342Z","shell.execute_reply":"2022-11-18T15:48:44.195322Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Define collate function that convert batch of raw strings into batch tensors that can be fed directly into model.","metadata":{}},{"cell_type":"code","source":"# helper function to club together sequential operations\ndef sequential_transforms(*transforms):\n    def func(txt_input):\n        for transform in transforms:\n            txt_input = transform(txt_input)\n        return txt_input\n    return func\n\n# function to add BOS/EOS and create tensor for input sequence indices\ndef tensor_transform(token_ids: List[int]):\n    return torch.cat((torch.tensor([BOS_IDX]),\n                      torch.tensor(token_ids),\n                      torch.tensor([EOS_IDX])))\n\n# src and tgt language text transforms to convert raw strings into tensors indices\ntext_transform = {}\nfor ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n                                               vocab_transform[ln], #Numericalization\n                                               tensor_transform) # Add BOS/EOS and create tensor\n\n\n\n     \n# function to collate data samples into batch tesors\ndef collate_fn(batch):\n    src_batch, tgt_batch = [], []\n    \n    for src_sample, tgt_sample in batch:\n        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n\n    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n    return src_batch, tgt_batch","metadata":{"execution":{"iopub.status.busy":"2022-11-18T15:48:44.199926Z","iopub.execute_input":"2022-11-18T15:48:44.200399Z","iopub.status.idle":"2022-11-18T15:48:44.209286Z","shell.execute_reply.started":"2022-11-18T15:48:44.200363Z","shell.execute_reply":"2022-11-18T15:48:44.208342Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Split data to train and test set","metadata":{}},{"cell_type":"code","source":"# Split data to tran test set\nsplit_ratio = 0.9\nsplit = round(df.shape[0]* split_ratio)\ntrain = df.iloc[:split]\ntrain_ds = list(zip(train['en'],train['vi']))\nvalid = df.iloc[split:]\nval_ds = list(zip(valid['en'],valid['vi']))","metadata":{"execution":{"iopub.status.busy":"2022-11-18T15:48:44.210634Z","iopub.execute_input":"2022-11-18T15:48:44.211477Z","iopub.status.idle":"2022-11-18T15:48:44.269638Z","shell.execute_reply.started":"2022-11-18T15:48:44.211443Z","shell.execute_reply":"2022-11-18T15:48:44.268598Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Define training and evaluation loop that will be called for each epoch with Gradient accumulation which is a technique where you can train on bigger batch sizes than your machine would normally be able to fit into memory. This is done by accumulating gradients over several batches, and only stepping the optimizer after a certain number of batches have been performed.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\naccumulation_steps = 5\n\ndef train_epoch(model, optimizer):\n    model.train()\n    losses = 0\n    val_los = 0\n    train_dataloader = DataLoader(train_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n    optimizer.zero_grad() \n    for i, (src, tgt) in enumerate(train_dataloader):\n        src = src.to(DEVICE)\n        tgt = tgt.to(DEVICE)\n\n        tgt_input = tgt[:-1, :]\n\n        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)   \n        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n\n        tgt_out = tgt[1:, :]\n        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n        loss = loss / accumulation_steps # Normalize our loss (if averaged)\n        loss.backward()\n        \n        if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n            optimizer.step() # Now we can do an optimizer step\n            optimizer.zero_grad() # Reset gradients tensor  \n\n        losses += loss.item()\n\n    return losses / len(train_dataloader)\n\ndef evaluate(model):\n    model.eval()\n    losses = 0\n\n    #val_iter = valid.iterrows()\n    val_dataloader = DataLoader(val_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n\n    for src, tgt in val_dataloader:\n        src = src.to(DEVICE)\n        tgt = tgt.to(DEVICE)\n\n        tgt_input = tgt[:-1, :]\n\n        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n\n        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n\n        tgt_out = tgt[1:, :]\n        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n        loss = loss / accumulation_steps # Normalize our loss (if averaged)\n        losses += loss.item()\n\n    return losses / len(val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-11-18T15:48:44.272754Z","iopub.execute_input":"2022-11-18T15:48:44.273067Z","iopub.status.idle":"2022-11-18T15:48:44.286401Z","shell.execute_reply.started":"2022-11-18T15:48:44.273040Z","shell.execute_reply":"2022-11-18T15:48:44.285439Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Define an early stopping function to avoid the model from overfit","metadata":{}},{"cell_type":"code","source":"class EarlyStopping():\n    def __init__(self, tolerance=5, min_delta=0):\n\n        self.tolerance = tolerance\n        self.min_delta = min_delta\n        self.counter = 0\n        self.early_stop = False\n\n    def __call__(self, train_loss, validation_loss):\n        if (validation_loss - train_loss) > self.min_delta:\n            self.counter +=1\n            if self.counter >= self.tolerance:  \n                self.early_stop = True","metadata":{"execution":{"iopub.status.busy":"2022-11-18T15:48:44.287632Z","iopub.execute_input":"2022-11-18T15:48:44.288716Z","iopub.status.idle":"2022-11-18T15:48:44.298738Z","shell.execute_reply.started":"2022-11-18T15:48:44.288679Z","shell.execute_reply":"2022-11-18T15:48:44.297681Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Training model","metadata":{}},{"cell_type":"code","source":"early_stopping = EarlyStopping(tolerance=5, min_delta=0.1)\nNUM_EPOCHS = 30\nhistory = {\n        \"loss\": [], \n        \"val_los\": []\n        }\n\nfor epoch in range(1, NUM_EPOCHS+1):\n    start_time = timer()\n    train_loss = train_epoch(transformer, optimizer)\n    end_time = timer()\n    val_loss = evaluate(transformer)\n    history['loss'].append(train_loss)\n    history['val_los'].append(val_loss)\n    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n    # Early Stopping\n    early_stopping(train_loss, val_loss)\n    if early_stopping.early_stop:\n        print(\"We are at epoch:\", epoch)\n        break","metadata":{"execution":{"iopub.status.busy":"2022-11-18T15:48:44.300303Z","iopub.execute_input":"2022-11-18T15:48:44.300805Z","iopub.status.idle":"2022-11-18T17:22:47.463379Z","shell.execute_reply.started":"2022-11-18T15:48:44.300771Z","shell.execute_reply":"2022-11-18T17:22:47.462326Z"},"_kg_hide-output":true,"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch: 1, Train loss: 0.940, Val loss: 0.627, Epoch time = 176.732s\nEpoch: 2, Train loss: 0.536, Val loss: 0.400, Epoch time = 174.989s\nEpoch: 3, Train loss: 0.379, Val loss: 0.308, Epoch time = 174.382s\nEpoch: 4, Train loss: 0.297, Val loss: 0.256, Epoch time = 174.051s\nEpoch: 5, Train loss: 0.245, Val loss: 0.223, Epoch time = 174.168s\nEpoch: 6, Train loss: 0.210, Val loss: 0.202, Epoch time = 175.297s\nEpoch: 7, Train loss: 0.184, Val loss: 0.186, Epoch time = 174.193s\nEpoch: 8, Train loss: 0.164, Val loss: 0.177, Epoch time = 174.420s\nEpoch: 9, Train loss: 0.147, Val loss: 0.166, Epoch time = 174.503s\nEpoch: 10, Train loss: 0.134, Val loss: 0.160, Epoch time = 174.014s\nEpoch: 11, Train loss: 0.122, Val loss: 0.155, Epoch time = 174.015s\nEpoch: 12, Train loss: 0.112, Val loss: 0.151, Epoch time = 177.406s\nEpoch: 13, Train loss: 0.104, Val loss: 0.148, Epoch time = 175.501s\nEpoch: 14, Train loss: 0.096, Val loss: 0.145, Epoch time = 175.107s\nEpoch: 15, Train loss: 0.090, Val loss: 0.145, Epoch time = 175.777s\nEpoch: 16, Train loss: 0.083, Val loss: 0.144, Epoch time = 176.362s\nEpoch: 17, Train loss: 0.078, Val loss: 0.142, Epoch time = 178.003s\nEpoch: 18, Train loss: 0.073, Val loss: 0.141, Epoch time = 176.875s\nEpoch: 19, Train loss: 0.068, Val loss: 0.140, Epoch time = 176.744s\nEpoch: 20, Train loss: 0.064, Val loss: 0.139, Epoch time = 176.355s\nEpoch: 21, Train loss: 0.060, Val loss: 0.140, Epoch time = 176.086s\nEpoch: 22, Train loss: 0.057, Val loss: 0.140, Epoch time = 175.753s\nEpoch: 23, Train loss: 0.053, Val loss: 0.139, Epoch time = 175.662s\nEpoch: 24, Train loss: 0.050, Val loss: 0.140, Epoch time = 175.776s\nEpoch: 25, Train loss: 0.048, Val loss: 0.139, Epoch time = 175.789s\nEpoch: 26, Train loss: 0.045, Val loss: 0.140, Epoch time = 175.197s\nEpoch: 27, Train loss: 0.043, Val loss: 0.141, Epoch time = 175.361s\nEpoch: 28, Train loss: 0.040, Val loss: 0.141, Epoch time = 174.737s\nEpoch: 29, Train loss: 0.038, Val loss: 0.142, Epoch time = 175.071s\nEpoch: 30, Train loss: 0.036, Val loss: 0.142, Epoch time = 175.098s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Traning and Validate plotting","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(history['loss'], label = \"loss\")\nplt.plot(history['val_los'], label = \"Val loss\")\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.title('Loss vs. No. of epochs');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-11-18T17:22:47.465062Z","iopub.execute_input":"2022-11-18T17:22:47.465404Z","iopub.status.idle":"2022-11-18T17:22:47.689074Z","shell.execute_reply.started":"2022-11-18T17:22:47.465370Z","shell.execute_reply":"2022-11-18T17:22:47.688379Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"**Inference**","metadata":{}},{"cell_type":"code","source":"# function to generate output sequence using greedy algorithm\ndef greedy_decode(model, src, src_mask, max_len, start_symbol):\n    src = src.to(DEVICE)\n    src_mask = src_mask.to(DEVICE)\n\n    memory = model.encode(src, src_mask)\n    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n    for i in range(max_len-1):\n        memory = memory.to(DEVICE)\n        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n                    .type(torch.bool)).to(DEVICE)\n        out = model.decode(ys, memory, tgt_mask)\n        out = out.transpose(0, 1)\n        prob = model.generator(out[:, -1])\n        _, next_word = torch.max(prob, dim=1)\n        next_word = next_word.item()\n\n        ys = torch.cat([ys,\n                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n        if next_word == EOS_IDX:\n            break\n    return ys\n\n\n# actual function to translate input sentence into target language\ndef translate(model: torch.nn.Module, src_sentence: str):\n    model.eval()\n    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n    num_tokens = src.shape[0]\n    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n    tgt_tokens = greedy_decode(\n        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")","metadata":{"execution":{"iopub.status.busy":"2022-11-18T17:22:47.690421Z","iopub.execute_input":"2022-11-18T17:22:47.691006Z","iopub.status.idle":"2022-11-18T17:22:47.701833Z","shell.execute_reply.started":"2022-11-18T17:22:47.690970Z","shell.execute_reply":"2022-11-18T17:22:47.700982Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Saving model\ntorch.save(transformer.state_dict(), \"viEn_transformer.pth\")","metadata":{"execution":{"iopub.status.busy":"2022-11-18T17:32:04.408042Z","iopub.execute_input":"2022-11-18T17:32:04.408417Z","iopub.status.idle":"2022-11-18T17:32:04.724038Z","shell.execute_reply.started":"2022-11-18T17:32:04.408387Z","shell.execute_reply":"2022-11-18T17:32:04.722931Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Testing model by randomly take 10 samples from the rest of the dataset","metadata":{}},{"cell_type":"code","source":"from random import randint\nrand = [randint(170000,200000) for i in range(10)]\ntest_set = [\n        [en_sents[i] for i in rand],\n        [vi_sents[i] for i in rand]]\n    \nfor i in range(len(test_set[0])):\n    print('Input English sentence:', test_set[0][i])\n    print('Actual Vietnamese Translation:', test_set[1][i])\n    print('Predicted Vietnamese Translation:', translate(transformer, test_set[0][i]))\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-11-18T17:23:45.201276Z","iopub.execute_input":"2022-11-18T17:23:45.201629Z","iopub.status.idle":"2022-11-18T17:23:45.716597Z","shell.execute_reply.started":"2022-11-18T17:23:45.201599Z","shell.execute_reply":"2022-11-18T17:23:45.715460Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Input English sentence: He tried it again, only to fail\nActual Vietnamese Translation: anh thử lại lần nữa, chỉ để thất bại\nPredicted Vietnamese Translation:  anh ấy đã thử nó một lần nữa chỉ để thất bại \n\n\nInput English sentence: This stone weighs five tons.\nActual Vietnamese Translation: hòn đá này nặng năm tấn.\nPredicted Vietnamese Translation:  hòn đá này nặng năm tấn sách \n\n\nInput English sentence: I wanna get out of here!\nActual Vietnamese Translation: tôi muốn ra khỏi đây\nPredicted Vietnamese Translation:  tôi muốn ra khỏi đây ngay \n\n\nInput English sentence: That stove smokes too much\nActual Vietnamese Translation: cái bếp đó hút quá nhiều\nPredicted Vietnamese Translation:  bếp đó hút thuốc quá nhiều \n\n\nInput English sentence: Compared to those around him, he looked really happy.\nActual Vietnamese Translation: so với những người xung quanh, anh ấy trông thực sự hạnh phúc.\nPredicted Vietnamese Translation:  so với những người xung quanh trông anh ta thực sự rất hạnh phúc khi thể hiện sự hạnh phúc \n\n\nInput English sentence: It is no use your pretending that you know nothing.\nActual Vietnamese Translation: nó không có ích gì khi bạn giả vờ rằng bạn không biết gì.\nPredicted Vietnamese Translation:  không có ích gì khi giả vờ rằng bạn không biết bất kỳ sự khác biệt nào \n\n\nInput English sentence: Tom doesn't have a house to live in.\nActual Vietnamese Translation: Tom không có nhà để ở.\nPredicted Vietnamese Translation:  tom mang theo các nhà vào mua một ngôi nhà để sống trong các thời gian ngắn \n\n\nInput English sentence: Tom took a deep breath and closed his eyes\nActual Vietnamese Translation: Tom hít một hơi thật sâu và nhắm mắt lại\nPredicted Vietnamese Translation:  tom hít một hơi thật sâu và nhắm mắt lại \n\n\nInput English sentence: Don't you want to sit in the front, Tom?\nActual Vietnamese Translation: bạn không muốn ngồi ở phía trước, tom?\nPredicted Vietnamese Translation:  đầu tư vào mùa xuân bạn muốn ngồi ở phòng ngay cả tay tom \n\n\nInput English sentence: I don't know why that's important.\nActual Vietnamese Translation: tôi không biết tại sao điều đó quan trọng.\nPredicted Vietnamese Translation:  tôi thích các gói quà tại sao các cửa hàng lại một số tiền thực sự quan trọng \n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"With a little effort we can deploy our own training model via API with fastAPI. Check out my demo by the link below\n\nhttps://youtu.be/OOJfZm6OpvI","metadata":{}},{"cell_type":"markdown","source":"**References**\n\nhttps://pytorch.org/tutorials/beginner/translation_transformer.html","metadata":{}}]}